#Problem 1

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay

#Load the dataset
url = 'https://raw.githubusercontent.com/HamedTabkhi/Intro-to-ML/main/Dataset/diabetes.csv'
data = pd.read_csv(url)

#Explore the dataset
print("First 5 rows of the dataset:\n", data.head())
print("\nDataset information:\n")
print(data.info())
print("\nStatistics of the dataset:\n")
print(data.describe())

#Preprocess the data (features and target, scaling)
X = data.drop(columns=['Outcome'])
y = data['Outcome']

#Standardize the features (scaling)
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

#Split dataset into training (80%) and test (20%) sets
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

#Build and Train the Logistic Regression model
log_reg = LogisticRegression(max_iter=1000)
log_reg.fit(X_train, y_train)

#Model Evaluation on test data
y_pred = log_reg.predict(X_test)

#Metrics calculations
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

#Displaying the results
print(f"Accuracy: {accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1 Score: {f1:.4f}")

#Plot Confusion Matrix
conf_matrix = confusion_matrix(y_test, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix)
disp.plot(cmap=plt.cm.Blues)
plt.title('Confusion Matrix')
plt.show()

#Problem 2 Part 1

from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np

#Loading the breast cancer dataset
data = load_breast_cancer()
X, y = data.data, data.target

#Splitting the data into training (80%) and test (20%) sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

#Standardizing the features (scaling)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

#Building the logistic regression model
log_reg = LogisticRegression(max_iter=10000)
log_reg.fit(X_train_scaled, y_train)

#Making predictions on the test set
y_pred = log_reg.predict(X_test_scaled)

#Calculating evaluation metrics
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

#Generating the confusion matrix
conf_matrix = confusion_matrix(y_test, y_pred)

#Plotting the confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=data.target_names, yticklabels=data.target_names)
plt.title("Confusion Matrix for Logistic Regression")
plt.ylabel('Actual')
plt.xlabel('Predicted')
plt.show()

#Displaying results
accuracy, precision, recall, f1

#Problem 2 Part 2

from sklearn.datasets import load_breast_cancer
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt

#Load the cancer dataset
cancer_data = load_breast_cancer()

#Create a DataFrame for the features and target
X = pd.DataFrame(cancer_data.data, columns=cancer_data.feature_names)
y = pd.Series(cancer_data.target)

#Split the dataset into training and testing sets (80% training, 20% testing)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

#Standardize the features (Z-score normalization)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

#Create and train a logistic regression model (no weight penalty)
log_reg = LogisticRegression(max_iter=10000)
log_reg.fit(X_train_scaled, y_train)

#Predict on the test set
y_pred = log_reg.predict(X_test_scaled)

#Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

#Print the results
print("Logistic Regression without Penalty:")
print(f"Accuracy: {accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1 Score: {f1:.4f}")

#Plot confusion matrix
cm = confusion_matrix(y_test, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=cancer_data.target_names)
disp.plot(cmap=plt.cm.Blues)
plt.title("Confusion Matrix (Without Weight Penalty)")
plt.show()

#Create and train a logistic regression model with weight penalty
log_reg_l2 = LogisticRegression(penalty='l2', C=1.0, max_iter=10000)
log_reg_l2.fit(X_train_scaled, y_train)

#Predict on the test set
y_pred_l2 = log_reg_l2.predict(X_test_scaled)

#Evaluate the regularized model
accuracy_l2 = accuracy_score(y_test, y_pred_l2)
precision_l2 = precision_score(y_test, y_pred_l2)
recall_l2 = recall_score(y_test, y_pred_l2)
f1_l2 = f1_score(y_test, y_pred_l2)

#Print the results
print("\nLogistic Regression with Weighted Penalty:")
print(f"Accuracy: {accuracy_l2:.4f}")
print(f"Precision: {precision_l2:.4f}")
print(f"Recall: {recall_l2:.4f}")
print(f"F1 Score: {f1_l2:.4f}")

# Plot confusion matrix for regularized model
cm_l2 = confusion_matrix(y_test, y_pred_l2)
disp_l2 = ConfusionMatrixDisplay(confusion_matrix=cm_l2, display_labels=cancer_data.target_names)
disp_l2.plot(cmap=plt.cm.Blues)
plt.title("Confusion Matrix (With Weighted Penalty)")
plt.show()

#Problem 3

import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report

#Load the dataset
cancer_data = load_breast_cancer()
X = cancer_data.data
y = cancer_data.target

#Split the data (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

#Naive Bayes Classifier
nb_model = GaussianNB()
nb_model.fit(X_train, y_train)
y_pred_nb = nb_model.predict(X_test)

#Logistic Regression Classifier for comparison
lr_model = LogisticRegression(max_iter=10000)
lr_model.fit(X_train, y_train)
y_pred_lr = lr_model.predict(X_test)

#Evaluate Naive Bayes Model
nb_accuracy = accuracy_score(y_test, y_pred_nb)
nb_precision = precision_score(y_test, y_pred_nb)
nb_recall = recall_score(y_test, y_pred_nb)
nb_f1 = f1_score(y_test, y_pred_nb)

#Evaluate Logistic Regression Model
lr_accuracy = accuracy_score(y_test, y_pred_lr)
lr_precision = precision_score(y_test, y_pred_lr)
lr_recall = recall_score(y_test, y_pred_lr)
lr_f1 = f1_score(y_test, y_pred_lr)

#Print results
print(f"Naive Bayes - Accuracy: {nb_accuracy:.4f}, Precision: {nb_precision:.4f}, Recall: {nb_recall:.4f}, F1: {nb_f1:.4f}")
print(f"Logistic Regression - Accuracy: {lr_accuracy:.4f}, Precision: {lr_precision:.4f}, Recall: {lr_recall:.4f}, F1: {lr_f1:.4f}")

#Classification Report for Naive Bayes
print("\nNaive Bayes Classification Report:")
print(classification_report(y_test, y_pred_nb))

#Confusion Matrix
cm_nb = confusion_matrix(y_test, y_pred_nb)
cm_lr = confusion_matrix(y_test, y_pred_lr)

#Plot confusion matrix for Naive Bayes
plt.figure(figsize=(10, 5))
plt.subplot(1, 2, 1)
plt.imshow(cm_nb, interpolation='nearest', cmap=plt.cm.Blues)
plt.title('Naive Bayes Confusion Matrix')
plt.colorbar()
plt.xlabel('Predicted label')
plt.ylabel('True label')

#Plot confusion matrix for Logistic Regression
plt.subplot(1, 2, 2)
plt.imshow(cm_lr, interpolation='nearest', cmap=plt.cm.Blues)
plt.title('Logistic Regression Confusion Matrix')
plt.colorbar()
plt.xlabel('Predicted label')
plt.ylabel('True label')

plt.tight_layout()
plt.show()

#Problem 4

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

#Load the cancer dataset
cancer = load_breast_cancer()
X = cancer.data
y = cancer.target

#Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

#Standardize the feature data
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

#Lists to store results
accuracies = []
precisions = []
recalls = []
f1_scores = []
K_values = range(1, 28)

for K in K_values:
    pca = PCA(n_components=K)
    X_train_pca = pca.fit_transform(X_train)
    X_test_pca = pca.transform(X_test)

    #Train logistic regression model
    model = LogisticRegression(max_iter=1000)
    model.fit(X_train_pca, y_train)

    #Make predictions
    y_pred = model.predict(X_test_pca)

    #Calculate evaluation metrics
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)

    #Append metrics to the lists
    accuracies.append(accuracy)
    precisions.append(precision)
    recalls.append(recall)
    f1_scores.append(f1)

#Plot accuracy, precision, recall, and F1 score
plt.figure(figsize=(12, 8))
plt.plot(K_values, accuracies, label='Accuracy', marker='o')
plt.plot(K_values, precisions, label='Precision', marker='o')
plt.plot(K_values, recalls, label='Recall', marker='o')
plt.plot(K_values, f1_scores, label='F1 Score', marker='o')

plt.title('Performance Metrics vs. Number of PCA Components')
plt.xlabel('Number of PCA Components(K)')
plt.ylabel('Score')
plt.legend()
plt.grid()
plt.show()

#Problem 5

import pandas as pd
import numpy as np
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score

#Load the breast cancer dataset from sklearn
data = load_breast_cancer()
X = data.data  # Features
y = data.target  # Target

#Split the dataset into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

#Initialize the logistic regression classifier
model = LogisticRegression(max_iter=1000)

#Fit the model
model.fit(X_train, y_train)

#Make predictions
y_pred = model.predict(X_test)

#Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

#Print the results
print("Logistic Regression Results:")
print(f"Accuracy: {accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1 Score: {f1:.4f}")

#Detailed classification report
print("\nClassification Report:")
print(classification_report(y_test, y_pred))
